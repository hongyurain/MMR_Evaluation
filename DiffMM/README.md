# DiffMM: Multi-Modal Diffusion Model for Recommendation

This is the PyTorch implementation for **DiffMM** proposed in the paper [**DiffMM: Multi-Modal Diffusion Model for Recommendation**](https://arxiv.org/abs/2406.11781), which is accepted by ACM MM 2024 Oral.


In this paper, we propose DiffMM, a new multi-modal recommendation model that enriches the probabilistic diffusion paradigm by incorporating modality awareness. Our approach utilizes a multi-modal graph diffusion model to reconstruct a comprehensive user-item graph, while harnessing the advantages of a cross-modal data augmen- tation module that provides valuable self-supervision signals. To assess the effectiveness of DiffMM, we conducted extensive experi- ments, comparing it to several competitive baselines. The results unequivocally establish the superiority of our approach in terms of recommendation performance, firmly establishing its efficacy.

## ğŸ“ Environment

We develop our codes in the following environment:

- python==3.9.13
- numpy==1.23.1
- torch==1.11.0
- scipy==1.9.1

## ğŸ¯ Experimental Results

Performance comparison of baselines on different datasets in terms of Recall@20, NDCG@20 and Precision@20:

<img src="./figures/performance.png" style="zoom:100%;" />

## ğŸš€ How to run the codes

The command lines to train DiffMM is as follow: 


- DY

```python
python Main.py --data DY --reg 1e-4 --ssl_reg 1e-2 --epoch 50 --trans 1 --e_loss 0.1 --cl_method 1
```

- Baby, Taobao

```python
python Main.py --data baby/taobao --reg 1e-5 --ssl_reg 1e-1 --keepRate 1 --e_loss 0.01
```

## ğŸ‘‰ Code Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ Main.py
â”œâ”€â”€ Model.py
â”œâ”€â”€ Params.py
â”œâ”€â”€ DataHandler.py
â”œâ”€â”€ Utils
â”‚Â Â  â”œâ”€â”€ TimeLogger.py
â”‚Â Â  â””â”€â”€ Utils.py
â”œâ”€â”€ figures
â”‚Â Â  â”œâ”€â”€ model.png
â”‚Â Â  â”œâ”€â”€ dataset.png
â”‚Â Â  â””â”€â”€ performance.png
â””â”€â”€ Datasets
    â”œâ”€â”€ tiktok
    â”‚Â Â  â”œâ”€â”€ trnMat.pkl
    â”‚Â Â  â”œâ”€â”€ tstMat.pkl
    â”‚Â Â  â”œâ”€â”€ valMat.pkl
    â”‚Â Â  â”œâ”€â”€ audio_feat.npy
    â”‚Â Â  â”œâ”€â”€ image_feat.npy
    â”‚   â””â”€â”€ text_feat.npy
    â”œâ”€â”€ baby
    â”‚Â Â  â”œâ”€â”€ trnMat.pkl
    â”‚Â Â  â”œâ”€â”€ tstMat.pkl
    â”‚Â Â  â”œâ”€â”€ valMat.pkl
    â”‚Â Â  â”œâ”€â”€ text_feat.npy
    â”‚   â””â”€â”€ image_feat.npy.zip
    â””â”€â”€ README.md
```


## ğŸŒŸ Citation

If you find this work helpful to your research, please kindly consider citing our paper.

```
@article{jiang2024diffmm,
  title={DiffMM: Multi-Modal Diffusion Model for Recommendation},
  author={Jiang, Yangqin and Xia, Lianghao and Wei, Wei and Luo, Da and Lin, Kangyi and Huang, Chao},
  journal={arXiv preprint arXiv:2406.11781},
  year={2024}
}
```

